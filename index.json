[{"authors":["admin"],"categories":null,"content":"Cloud Engineer with a demonstrated history working in Google Cloud Big Data Stack \u0026amp; Web Analytics; from collection of data to building informative dashboards. Had experience working in OTT and E-commerce domains.\nDuring free time love to design generative art using Processing, P5js, and oF, exploring new technologies and learning new programming languages.\n","date":1591284346,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1591284346,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://1by2.github.io/author/darsh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/darsh/","section":"authors","summary":"Cloud Engineer with a demonstrated history working in Google Cloud Big Data Stack \u0026amp; Web Analytics; from collection of data to building informative dashboards. Had experience working in OTT and E-commerce domains.","tags":null,"title":"Darsh","type":"authors"},{"authors":["Darsh"],"categories":["data-engineering"],"content":"Data Lake A central place where all company\u0026rsquo;s raw data flows, rapidly.\nIt is intended to be raw data - as close to the source as possible. It is still a good idea to capture the meta data and describe the data so that people can explore the lake and re-use what is available.\nData Lake comprises of these 5 major principles Ingest Ability to collect all data that business care about. Systems frequently ingest data through APIs and batch processing.\nStore Getting all data in one place and breaking down data silos. The storage should be scalable that supports storing structured, unstructured, and semistructured data.\nAnalyze Matching correct data point and having correct systems and finding relations between all data gathered. Schema is written at the time of analysis (schema on read)\nSurface There needs to be a simple method to display all analysis. The data need to be understand here; the easier to see the result the easier to take actions.\nAct \u0026quot;Make Me More Money\u0026quot;. A plan has to be put in place to take the results of data analysis and fit it into an operation business model.\nThe main challenge with a data lake architecture Raw data is stored with no oversight of the contents. For a data lake to make data usable, it needs to have defined mechanisms to catalog, and secure data. Without these elements, data cannot be found, or trusted resulting in a “data swamp.\u0026rdquo;\n For those who are thinking that how Data Warehouse is different from a Data Lake, well to put it succinctly, proving the value of data is the role of Data Lake and In Data Warehouse one\u0026rsquo;s valuable data resides which they use for reporting purposes.\n Which one to use Data Lake or Data Warehouse? Big Data isn\u0026rsquo;t a singular term. Every architecture and every technology underline has their unique use case. So in other words use the best tool for the job.\n","date":1591284346,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591284346,"objectID":"a2c7a05b602a4af197a3346d83802e08","permalink":"https://1by2.github.io/post/data-engineering/data-lake/","publishdate":"2020-06-04T20:55:46+05:30","relpermalink":"/post/data-engineering/data-lake/","section":"post","summary":"A central place where all company's raw data flows, rapidly.","tags":["Data Engineering","Data lake"],"title":"Introduction: Data lake","type":"post"},{"authors":["Darsh"],"categories":["data-engineering"],"content":"Data Warehouse A central repository of information that can be analyzed to make informed decisions. Data flows into a data warehouse from transactional systems, relational databases, and other sources.\nThe core architecture boils down to some - Pre-Processing When data collection is from a number of different sources. Consistency in the format is essential before loading into a data warehouse.\nStaging A holding area, where you put data after pre-processing (but not always) — and store it transiently until it’s processed further down the line. This is the last point where the data should be found in its raw form. (Amazon s3, Google Cloud Storage, etc are useful cloud products for staging area)\nMaster The master area is where the incoming data takes some real shape. The master schema should contain correctly modeled tables, that are appropriately named. Data Cleaning is mostly done here.\nReporting Business analysts, data scientists, and decision-makers access the data through business intelligence (BI) tools, SQL clients, and other analytics applications. Businesses use reports, dashboards, and analytics tools to extract insights from their data, monitor business performance, and support decision making. These reports, dashboards, and analytics tools are powered by data warehouses. (To analyze data Amazon Redshift, Google Bigquery, etc are useful big data cloud products)\nKey Points Data Warehouse consists of highly curated data that serves as the central version of the truth, the data schema is designed prior DW implementation (schema-on-write). Used for batch reporting, business intelligence, and data visualization by business analyst.\n","date":1591279169,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591279169,"objectID":"9be303a378d08cf9ff7e6ef56bc2eef8","permalink":"https://1by2.github.io/post/data-engineering/data-warehouse/","publishdate":"2020-06-04T19:29:29+05:30","relpermalink":"/post/data-engineering/data-warehouse/","section":"post","summary":"A data warehouse is constructed by integrating data from heterogeneous sources such as relational databases, flat files, etc.","tags":["Data Engineering","Data warehouse"],"title":"Introduction: Data warehouse","type":"post"},{"authors":["Darsh"],"categories":["python"],"content":"If you don\u0026rsquo;t know about What generator is ? Please have a look at this post. Let’s, deep dive! Understanding Subroutine When the logic for a function with complex behavior is divided into several small steps that are themselves functions, these functions are called helper functions or subroutines. Subroutines are called by the main function that is responsible for coordinating the use of several subroutines.\nUnderstanding Coroutine There is another approach for dividing or decomposing a complex program. In the above approach, we have only one entry point, the main function. Using coroutines we will have one entry point but multiple re-entry points. When using coroutines, there is no main function to coordinate results. Instead, coroutines themselves link together to form a pipeline. There may be a coroutine for consuming the incoming data and sending it to other coroutines. There may be coroutines that each do simple processing steps on data sent to them, and there may finally be another coroutine that outputs a final result.\nLet’s explore how python supports building coroutines with the yield and send() statements.\nSo far we have seen that python generator function yield a value. But it can also consume a value using (yield). Apart from yield and next(), the generator object also have send() and close() functions.\n\u0026gt;\u0026gt;\u0026gt; value = (yield)\r PEP 342 explains the exact rules, which are that a yield-expression must always be parenthesized except when it occurs at the top-level expression on the right-hand side of an assignment. With this statement, execution pauses until the object\u0026rsquo;s send method is invoked with an argument\n\u0026gt;\u0026gt;\u0026gt; coroutine.send(data)\r Then, execution resumes, with the value being assigned to the value of data.\nLet’s look at an example to clarify things up: We will design two functions. The first function emit_word() will produce words from the given input string and emit/send our second function pattern() will consume the input word and will give the output if a pattern p is in the input word.\nConsumer: # Consumer\r\u0026gt;\u0026gt;\u0026gt; def pattern(p):\rprint(f\u0026quot;Searching for {p}\u0026quot;)\rtry:\rwhile True:\rs = (yield)\rif p in s:\rprint(s)\rexcept GeneratorExit:\rprint(\u0026quot;=== Completed ===\u0026quot;)\r Examining the consumer functioin: \u0026gt;\u0026gt;\u0026gt; p = pattern(\u0026quot;apple\u0026quot;)\r\u0026gt;\u0026gt;\u0026gt; next(p)\rSeraching for apple\r# The generator function will pause until send() is called.\r\u0026gt;\u0026gt;\u0026gt; p.send(\u0026quot;An apple a day keeps the doctor away\u0026quot;)\rAn apple a day keeps the doctor away\r\u0026gt;\u0026gt;\u0026gt; p.send(\u0026quot;A strawberry a day keeps the doctor away\u0026quot;)\r\u0026gt;\u0026gt;\u0026gt; p.send(\u0026quot;My mom gave me an apple\u0026quot;)\rMy mom gave me an apple\r\u0026gt;\u0026gt;\u0026gt; p.close()\r===Completed===\r Producer: #Producer\r\u0026gt;\u0026gt;\u0026gt; def emit_word(string, match):\rfor word in string.split():\rmatch.send(word)\rmatch.close()\r Examining the producer functioin: For each word in a given string it emits/send the word to the consumer function\nJoining all together: \u0026gt;\u0026gt;\u0026gt; string = \u0026quot;Pen Pineapple apple pen\u0026quot;\r\u0026gt;\u0026gt;\u0026gt; match = pattern(\u0026quot;apple\u0026quot;)\r\u0026gt;\u0026gt;\u0026gt; next(match)\rSeraching for apple\r\u0026gt;\u0026gt;\u0026gt; emit_word(string, match)\rPineapple\rapple\r===Completed===\r Key takeaways: generators  Generators produce values one-at-a-time as opposed to giving them all at once. There are two ways to create generators: generator functions and generator expressions. Generator functions yield, regular functions return. Generator expressions need (), list comprehensions use []. You can only use generator expressions once. There are two ways to get values from generators: the next() function and a for loop. The for loop is often the preferred method. We can use generators to read huge files to give us one line at a time. By not loading everything in memory at once.  ","date":1590662708,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590662708,"objectID":"72a5f5c801582a52cbee86600025af41","permalink":"https://1by2.github.io/post/python/generator2/","publishdate":"2020-05-28T16:15:08+05:30","relpermalink":"/post/python/generator2/","section":"post","summary":"Decomposing complex program into sophisticated pipelines","tags":["Python","Generators","Subroutine","Coroutine"],"title":"Part 2 Generator: Python Coroutine","type":"post"},{"authors":["Darsh"],"categories":["python"],"content":"Generator Before starting with what generators are, we’ll first discuss what iteration, iterables, and iterators are.\nIteration Iteration is a term for taking each item of something, one after another. Any time you use a loop, explicit or implicit, to go over a group of items, that is iteration.\nIterable Iterable is an object that is, well, iterable, which simply means that it can be used in iteration, e.g. with a for loop. How? By using an iterator. I\u0026rsquo;ll explain it below. Iterable objects also define __iter__ that returns an iterator, and also have a __getitem__ method suitable for indexed lookup. Examples of iterables include lists, tuples, and strings - any such sequence that can be iterated over a loop.\nIterator Iterator is an object that defines how to actually do the iteration, specifically what is the next element. That\u0026rsquo;s why it must have the next() method. It remembers where it is during iteration.\nLet’s look an example to clarify things up: \u0026gt;\u0026gt;\u0026gt; # ranks is an iterable\r\u0026gt;\u0026gt;\u0026gt; ranks = [1,2,3]\r\u0026gt;\u0026gt;\u0026gt; # Returns True ranks has __iter__ method\r\u0026gt;\u0026gt;\u0026gt; __iter__ in dir(ranks)\rTrue\r\u0026gt;\u0026gt;\u0026gt; # Returns True ranks has __getitem__ method\r\u0026gt;\u0026gt;\u0026gt; __getitem__ in dir(ranks)\rTrue\r\u0026gt;\u0026gt;\u0026gt; # ranks is now an iterator\r\u0026gt;\u0026gt;\u0026gt; ranks = iter(ranks)\r\u0026gt;\u0026gt;\u0026gt; # Retuns True ranks has __next__ method\r\u0026gt;\u0026gt;\u0026gt; __next__ in dir(ranks)\rTrue\r\u0026gt;\u0026gt;\u0026gt; next(ranks)\r1\r\u0026gt;\u0026gt;\u0026gt; next(ranks)\r2\r\u0026gt;\u0026gt;\u0026gt; next(ranks)\r3\r\u0026gt;\u0026gt;\u0026gt; # next() raises StopIteration, to signal that iteration is complete\r\u0026gt;\u0026gt;\u0026gt; next(ranks)\rTraceback (most recent call last):\rFile \u0026quot;\u0026lt;stdin\u0026gt;\u0026quot;, line 1, in \u0026lt;module\u0026gt;\rStopIteration\r Whenever we use a for loop, or map, or a list comprehension, etc. in Python, the next method is called automatically to get each item from the iterator, thus going through the process of iteration.\nWith our knowledge of iterators, we can implement the evaluation rule of a for statement in terms of while, assignment, and try statements.\n\u0026gt;\u0026gt;\u0026gt; i = ranks.__iter__() # or iter(ranks)\r\u0026gt;\u0026gt;\u0026gt; try:\rwhile True:\ritem = i.__next__() # or next(i)\rprint(item)\rexcept StopIteration:\rpass\r1\r2\r3\r In the above example if we want to keep track of our iteration we need to introduce a new field current to keep track of progress through the sequence. With simple sequences like one shown above, this can be done easily. With complex sequences, however, it can be quite difficult for the next() function to save its place in the calculation. Hence, comes generators allowing us to define more complicated iterations.\nWhat is a generator? A generator is an iterator returned by a special class of function called a generator function. Generator functions are distinguished from regular functions in that rather than containing return statements in their body, they use yield statement to return elements of a series.\n\u0026gt;\u0026gt;\u0026gt; def countdown(n): while n \u0026gt; 0: yield n n -= 1 \u0026gt;\u0026gt;\u0026gt; for i in countdown(5):\rprint(i, end=' ')\r5 4 3 2 1\r Above, the behavior is different from normal functions. Calling a generator function creates a generator object.\n\u0026gt;\u0026gt;\u0026gt; def countdown(n): while n \u0026gt; 0: yield n n -= 1 \u0026gt;\u0026gt;\u0026gt; c = countdown(5)\r\u0026lt;generator object countdown at 0x0000017CD6788360\u0026gt;\r The function only executes on next()\n\u0026gt;\u0026gt;\u0026gt; next(c)\r5\r\u0026gt;\u0026gt; \u0026gt;next(c)\r4\r# and so on until next() raises StopIteration\r A generator is kinda different from objects that support iteration. We can iterate over the generated data once, but if we want to do it again, we have to call the generator function again (resetting generator).\nLike list comprehensions, generators also support concise notions for such operations. Using ‘()’ \n\u0026gt;\u0026gt;\u0026gt; gen = (expression for i in s if condition)\r Note: In the above countdown example it doesn’t start running the function. It only computes when we request for data (The technical term for this behavior is lazy evaluation). Therefore not loading everything at once in in-memory is a useful perk of generators that we can exploit while dealing with a huge amount of data. We can model sequences with no definite end using generators\nBelow is an example of an infinite sequence of even numbers \u0026gt;\u0026gt;\u0026gt; def infinte_range(step):\ri = 0\rwhile True:\ryield i\ri += step\r\u0026gt;\u0026gt;\u0026gt; even_numbers = (x for x in infinte_range(2))\r\u0026gt;\u0026gt;\u0026gt; next(even_numbers)\r0\r\u0026gt;\u0026gt;\u0026gt; next(even_numbers)\r2\r\u0026gt;\u0026gt;\u0026gt; next(even_numbers)\r4\r\u0026gt;\u0026gt;\u0026gt; next(even_numbers)\r6\r To be continued\u0026hellip;\n","date":1590645695,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590645695,"objectID":"a4e3b40ed2e579a01154a4d4e4143391","permalink":"https://1by2.github.io/post/python/generator/","publishdate":"2020-05-28T11:31:35+05:30","relpermalink":"/post/python/generator/","section":"post","summary":"Understanding the powerful feature of python","tags":["Python","Iterators","Lazy Evaluation","Generators","yield"],"title":"Part 1 Generator: Introduction","type":"post"}]